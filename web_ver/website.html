<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Fool the AI!</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      background-color: #f5f5f5;
      padding: 20px;
    }

    video {
      border: 7px solid rgb(29, 172, 255);
      border-radius: 4px;
      background: #000;
    }

    #controls {
      margin: 20px;
    }

    button {
      font-size: 20px;
      padding: 10px 20px;
      margin: 10px;
      cursor: pointer;
    }

    #message {
      font-size: 24px;
      margin: 20px;
      color: #063544;
      font-weight: bold;
    }

    .image-box {
      width: 10vw;
      border: 7px solid #67a4ff;
      margin: 10px;
      display: inline-block;
      background: #eee;
      overflow: hidden;
      text-align: center;
    }

    .image-box img {
      width: 100%;
      height: auto; /* Let the image size adjust naturally */
      display: block;
    }

    .distance {
      margin-top: 5px;
      font-size: 16px;
      color: #333;
    }

  </style>
</head>
<body>
  <h1 id="title">Fool the AI!</h1>

  <video id="live-stream" width="640" height="360" autoplay muted></video>

  <div id="controls">
    <button id="captureBtn">Take a Picture!</button>
    
  </div>

  <div id="message">Please capture a training image.</div>

  <div>
    <div id="trainingBox1" class="image-box">Training Image 1</div>
    <div id="trainingBox2" class="image-box">Training Image 2</div>
    <div id="trainingBox3" class="image-box">Training Image 3</div>
    <div id="testBox" class="image-box">Test Image</div>
  </div>

  <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@latest/dist/face-api.min.js"></script>

  <script>let trainingDescriptors = []; // Array to store up to 3 training descriptors
let trainingImageURLs = [];

const THRESHOLD = 0.6;

const video = document.getElementById('live-stream');
const captureBtn = document.getElementById('captureBtn');
const messageEl = document.getElementById('message');
const trainingBoxes = [
    document.getElementById('trainingBox1'),
    document.getElementById('trainingBox2'),
    document.getElementById('trainingBox3')
];
const testBox = document.getElementById('testBox');
const title = document.getElementById('title');

function normalizeDescriptor(descriptor) {
    const norm = Math.sqrt(descriptor.reduce((sum, val) => sum + val * val, 0));
    return Float32Array.from(descriptor, val => val / norm);
}

async function loadModels() {
    await faceapi.nets.ssdMobilenetv1.loadFromUri('./wp-content/models/ssd_mobilenetv1');
    await faceapi.nets.faceLandmark68Net.loadFromUri('./wp-content/models/face_landmark_68');
    await faceapi.nets.faceRecognitionNet.loadFromUri('./wp-content/models/face_recognition');
    console.log("Models loaded");
}

async function startVideo() {
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        // Requests access to camera
        // Returns a MediaStream object (represents the camera feed)
        navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
            // Sets the video (element) source to the camera stream
            video.srcObject = stream;
        })
        .catch((error) => {
            console.error("Error accessing the camera: ", error);
        });
    } else {
        console.log("Could not access the webcam. Please check your browser permissions.");
    }
}

async function captureImage() {
    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    return canvas;
}

captureBtn.addEventListener('click', async () => {
    const canvas = await captureImage();
    const detection = await faceapi
    .detectSingleFace(canvas, new faceapi.SsdMobilenetv1Options())
    .withFaceLandmarks()
    .withFaceDescriptor();

    if (!detection) {
        alert("No face detected! Please try again.");
        return;
    } else; {
        console.log("Descriptor length:", detection.descriptor.length);
        console.log("Descriptor sample:", detection.descriptor.slice(0, 5));
    }

    const normalizedDescriptor = normalizeDescriptor(detection.descriptor);
    const dataURL = canvas.toDataURL('image/jpeg');

    if (trainingDescriptors.length < 3) {
        trainingDescriptors.push(normalizedDescriptor);
        trainingImageURLs.push(dataURL);

        trainingBoxes[trainingDescriptors.length - 1].innerHTML =
        `<img src="${canvas.toDataURL('image/jpeg')}" width="100%" height="100%">`;
        if (trainingDescriptors.length < 3) {
            messageEl.innerText = `Training image captured. Please capture ${3 - trainingDescriptors.length} more training image${3 - trainingDescriptors.length > 1 ? 's' : ''}.`;
        } else {
            messageEl.innerText = "All training images captured. Now try to fool the AI!";
        }

    } else {
        testBox.innerHTML = `<img src="${canvas.toDataURL('image/jpeg')}" width="100%" height="100%">`;

        const labeledDescriptor = new faceapi.LabeledFaceDescriptors("User", trainingDescriptors);
        const faceMatcher = new faceapi.FaceMatcher([labeledDescriptor], THRESHOLD);
        const bestMatch = faceMatcher.findBestMatch(normalizedDescriptor);

        let matchCount = 0;
        const distances = [];
        trainingDescriptors.forEach(desc => {
            const distance = faceapi.euclideanDistance(desc, normalizedDescriptor);
            distances.push(distance);
            if (distance < THRESHOLD) {
                matchCount++;
            }
        });

        trainingBoxes.forEach((box, idx) => {
            box.innerHTML = `
              <img src="${trainingImageURLs[idx]}" width="100%" height="100%">
              <div class="distance">Distance: ${distances[idx].toFixed(2)}</div>
            `;
          });

        if (matchCount >= 2) {
            messageEl.innerText = `I recognize you! Majority match count: ${matchCount} out of 3.`;
        } else {
            messageEl.innerText = `You fooled me! Not enough matches (only ${matchCount} out of 3).`;
        }
        
        showFinalButtons();
        }
});

function showFinalButtons() {
    document.getElementById('controls').innerHTML = `
        <button id="retryBtn">Retry</button>
        <button id="restartBtn">Restart</button>
    `;

    document.getElementById('retryBtn').addEventListener('click', () => {
        testBox.innerHTML = "Test Image";
        messageEl.innerText = "Take a new test image!";
        document.getElementById('controls').innerHTML = '<button id="captureBtn">Take a Picture!</button>';
        document.getElementById('captureBtn').addEventListener('click', async () => captureBtn.click());
    });

    document.getElementById('restartBtn').addEventListener('click', () => {
        trainingDescriptors = [];
        trainingImageURLs = [];
        trainingBoxes.forEach(box => box.innerHTML = "Training Image");
        testBox.innerHTML = "Test Image";
        messageEl.innerText = "Please take a training image.";
        document.getElementById('controls').innerHTML = '<button id="captureBtn">Take a Picture!</button>';
        document.getElementById('captureBtn').addEventListener('click', async () => captureBtn.click());
    });
}

window.addEventListener('load', async () => {
    await loadModels();
    startVideo();
});</script>
</body>
</html>